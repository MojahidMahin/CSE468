# Medical Image Captioning for ROCOv2-radiology Dataset

## Overview

This guide describes the medical image captioning pipeline for the **ROCOv2-radiology** dataset - a large-scale medical imaging dataset containing ~80,000 radiological images with captions.

The pipeline generates detailed medical image descriptions using **Qwen2-VL-2B**, a Vision-Language Model optimized for understanding and describing medical images.

## Dataset Information

### ROCOv2-radiology Dataset
- **Total Images**: 79,789 radiological images
- **Training Set**: 59,962 images
- **Validation Set**: 9,904 images
- **Test Set**: 9,927 images
- **Modalities**: CT, MRI, X-ray, ultrasound, and other radiological images
- **License**: CC BY-NC-SA 4.0
- **Location**: `/home/vortex/CSE 468 AFE/Datasets/ROCOv2-radiology/`

### Dataset Format
Images and metadata are stored in **Apache Parquet** format:
- Training: 27 parquet files
- Validation: 1 parquet file
- Test: 6 parquet files

Each record contains:
- `image`: PIL Image object
- `image_id`: Unique identifier
- `caption`: Original caption from PMC publications
- `cui`: Medical concepts (UMLS Concept Unique Identifiers)

## Script: `medical_image_captioning.py`

### Key Components

#### 1. **MedicalConfig Class**
Central configuration for the entire pipeline:
```python
DATASET_PATH = '/home/vortex/CSE 468 AFE/Datasets/ROCOv2-radiology'
RESULTS_DIR = '/home/vortex/CSE 468 AFE/Project/results_medical'
NUM_IMAGES = 50  # Adjust based on available resources
SPLIT = 'train'  # 'train', 'validation', or 'test'
DEVICE = 'cuda'  # Automatic GPU detection
DTYPE = torch.float16  # Float16 for memory efficiency
MODEL_NAME = 'Qwen/Qwen2-VL-2B-Instruct'
```

#### 2. **MedicalVLMCaptioner Class**
Handles model initialization and caption generation:
- Loads Qwen2-VL-2B-Instruct model from HuggingFace
- Processes medical images with medical-specific prompts
- Manages GPU memory efficiently using float16 precision
- Automatic model cleanup after use

Key method: `generate_caption(image)`
- Input: PIL Image object
- Output: Generated caption (string) and processing time (float)

#### 3. **ROCOv2Processor Class**
Manages dataset loading:
- Loads specified split (train/validation/test) from parquet files
- Returns batches of images for processing
- Preserves original metadata

### Configuration Options

To modify processing settings, edit the `MedicalConfig` class:

```python
class MedicalConfig:
    NUM_IMAGES = 100  # Process 100 images
    SPLIT = 'validation'  # Use validation set
```

## Running the Pipeline

### Quick Start
```bash
cd "/home/vortex/CSE 468 AFE/Project"
python medical_image_captioning.py
```

### Default Configuration
- **Images**: 50 from training set
- **Model**: Qwen2-VL-2B-Instruct
- **Output**: `results_medical/medical_captions_train.csv`

### Processing Speed
- **Average**: ~6 seconds per image
- **RTX 5080 VRAM**: ~6.5 GB during inference
- **Processing 50 images**: ~5-6 minutes

## Output Format

### CSV Result Files
Results are saved with the following columns:

| Column | Description |
|--------|-------------|
| `image_id` | Unique image identifier from ROCOv2 |
| `original_caption` | Original caption from PMC publication |
| `generated_caption` | Caption generated by Qwen2-VL-2B |
| `processing_time_sec` | Time to generate caption in seconds |
| `model` | Model name (Qwen/Qwen2-VL-2B-Instruct) |
| `timestamp` | UTC timestamp of generation |
| `split` | Dataset split (train/validation/test) |

### Output Files
1. **Main Result**: `results_medical/medical_captions_{SPLIT}.csv`
   - Contains all processed images and their captions
   - Overwrites previous results from same split

2. **Checkpoints**: `results_medical/checkpoint_*.csv`
   - Saved every 25 images for recovery
   - Useful if processing is interrupted

## Model Information

### Qwen2-VL-2B-Instruct
- **Type**: Vision-Language Model
- **Parameters**: 2 billion
- **VRAM Required**: 5-7 GB
- **Precision**: Float16
- **Architecture**: Transformer-based with vision encoder
- **Training Data**: Diverse multi-modal data including medical images
- **Capabilities**:
  - Image understanding and description
  - Medical terminology recognition
  - Detailed anatomical analysis
  - Question-answering on images

### Why This Model?
- Efficient size (2B parameters) fits on 16GB RTX 5080
- Proven performance on medical image understanding
- Pre-trained on diverse medical imaging data
- Good balance of speed (~6 sec/image) and quality

## Testing Results

### Test Run (50 images from training set)
```
Total Images Processed: 50
Average Processing Time: 5.88 seconds
Processing Duration: ~5 minutes
```

### Sample Comparisons

#### Example 1: CT Head Scan
- **Image ID**: ROCOv2_2023_train_000001
- **Original**: "Head CT demonstrating left parotiditis."
- **Generated**: "This medical image is a computed tomography (CT) scan of the neck region. The scan shows various anatomical structures within the neck, including the skull, the spinal cord, the spinal canal, the vertebral column, and the surrounding soft tissues..."

#### Example 2: Renal Ultrasound
- **Image ID**: ROCOv2_2023_train_000002
- **Original**: "Acquired renal cysts in end-stage renal failure: 16-year-old girl with Alport syndrome and peritoneal dialysis from the age of 2 years"
- **Generated**: "The medical image appears to be an ultrasound scan, specifically a grayscale ultrasound image. Ultrasound scans are used to visualize internal structures of the body, such as the heart, liver, and kidneys..."

## Processing Large Datasets

### For Full Training Set (59,962 images)
Estimated processing time: **~100 hours** (4+ days non-stop)

To process in batches:

```python
# Process 500 images at a time
CONFIG.NUM_IMAGES = 500
# Run script multiple times, changing SPLIT or starting index
```

### Memory Management
The script automatically:
- Uses `device_map='auto'` for distributed GPU memory
- Employs float16 precision to reduce VRAM usage
- Calls `gc.collect()` and `torch.cuda.empty_cache()` between operations
- Unloads model after processing

### Optimization Tips
1. For faster processing: Reduce `max_new_tokens` from 256 to 128
2. For better quality: Increase `max_new_tokens` to 512
3. For parallel processing: Run multiple instances with different splits
4. For memory issues: Process fewer images per run (NUM_IMAGES = 25)

## Common Issues & Solutions

### Issue: CUDA Out of Memory (OOM)
**Solution**:
```python
NUM_IMAGES = 10  # Reduce batch size
# or use CPU
DEVICE = 'cpu'
```

### Issue: Slow Processing
**Solution**:
- Ensure no other CUDA processes are running
- Check available VRAM: `nvidia-smi`
- Close other applications

### Issue: Model Download Fails
**Solution**:
- Requires stable internet (model is ~5 GB)
- Models cache to `.cache/huggingface/`
- First run takes longer due to download

### Issue: Empty Captions
**Solution**:
- Check image format (PNG, JPG supported)
- Verify image isn't corrupted
- Try different image from batch

## Advanced Usage

### Custom Prompts
Edit the prompt in `generate_caption()` method:

```python
# Current
"Describe this medical image in detail."

# Alternative prompts:
"What medical condition is shown in this image?"
"Analyze the radiological findings in this image."
"List all anatomical structures visible in this image."
```

### Batch Processing
Process multiple splits sequentially:

```python
for split in ['train', 'validation', 'test']:
    MedicalConfig.SPLIT = split
    process_medical_images()
```

### Model Comparison
Test other models:

```python
# Try other VLMs:
MODEL_OPTIONS = [
    'Qwen/Qwen2-VL-2B-Instruct',
    'OpenGVLab/InternVL2-2B',  # 4-6 GB, faster
    'HuggingFaceM4/SmolVLM2-256M',  # Ultra-efficient
]
```

## Performance Metrics

| Metric | Value |
|--------|-------|
| Model Load Time | ~15 seconds |
| Per-Image Processing | 3.76-6.58 seconds |
| Average Speed | ~1 image / 6 seconds |
| VRAM Usage Peak | ~6.5 GB |
| Output CSV Size (50 images) | ~68 KB |

## Citation

If using this pipeline in research, cite the ROCOv2 dataset:

```bibtex
@misc{ronan_l.m._2024,
    author       = { {Ronan L.M.} },
    title        = { ROCOv2-radiology (Revision 5d66908) },
    year         = 2024,
    url          = { https://huggingface.co/datasets/eltorio/ROCOv2-radiology },
    doi          = { 10.57967/hf/3489 },
    publisher    = { Hugging Face }
}
```

## Next Steps

1. **Full Dataset Processing**: Scale to 59,962 training images
2. **Quality Evaluation**: Compare generated captions with originals using BLEU/METEOR metrics
3. **Model Fine-tuning**: Fine-tune on medical captions for improved domain performance
4. **Multi-Model Comparison**: Test with InternVL2, SmolVLM2, and other medical VLMs
5. **Production Deployment**: Export model for inference API

## Support

For issues or questions:
1. Check error messages in console output
2. Review this guide's troubleshooting section
3. Verify VRAM availability with `nvidia-smi`
4. Check dataset integrity: `ls /home/vortex/CSE 468 AFE/Datasets/ROCOv2-radiology/data/`

---

**Generated**: November 28, 2024
**Status**: Tested and working on RTX 5080
**Dataset**: ROCOv2-radiology v2 (79,789 images)
